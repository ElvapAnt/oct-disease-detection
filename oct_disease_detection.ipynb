{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f4ba6aa-117f-48bf-86ca-d3762310b10e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5653376-33f7-4173-8bab-00d8f7f75c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "\n",
    "import csv\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras_hub\n",
    "\n",
    "from keras_hub.layers import ViTImageConverter\n",
    "from keras_hub.models import ViTImageClassifierPreprocessor, ViTBackbone\n",
    "\n",
    "labels = \"annotations.csv\"\n",
    "train_path = \"deep_learning/working/Diabetic Retinopathy/train\"\n",
    "valid_path = \"deep_learning/working/Diabetic Retinopathy/valid\"\n",
    "test_path = \"deep_learning/working/Diabetic Retinopathy/test\"\n",
    "train_labels = os.path.join(train_path, labels)\n",
    "valid_labels = os.path.join(valid_path, labels)\n",
    "test_labels = os.path.join(test_path, labels)\n",
    "\n",
    "print(train_labels)\n",
    "print(valid_labels)\n",
    "print(test_labels)\n",
    "\n",
    "BINARY_LABEL_COL = \"Risk of macular edema\"\n",
    "\n",
    "# print(tf.keras.__version__)\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eda71d-a54f-44c9-bc27-3ea78decec3e",
   "metadata": {},
   "source": [
    "## 0. Dataset Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f95b58-f6bd-4500-942e-860b7d64e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts_from_dataset_split(split_annotations_path: str):\n",
    "    split_dir = Path(split_annotations_path)\n",
    "    labels = pd.read_csv(split_dir, usecols=[BINARY_LABEL_COL])[BINARY_LABEL_COL].astype(int)\n",
    "    counts = labels.value_counts().reindex([0, 1], fill_value=0)\n",
    "    return int(counts[0]), int(counts[1])\n",
    "\n",
    "def show_dataset_split_summary(name: str, negatives: int, positives: int):\n",
    "    total = negatives + positives\n",
    "    positive_pct = (positives / total) * 100 if total else 0.0\n",
    "    print(f\"{name:<6}  N={total:4d} | neg={negatives:4d}  pos={positives:4d}  pos%={positive_pct:6.2f}\")\n",
    "\n",
    "def show_class_balance(train_labels, valid_labels, test_labels, save_png=\"class_balance.png\"):\n",
    "    train_neg, train_pos = counts_from_dataset_split(train_labels)\n",
    "    valid_neg, valid_pos = counts_from_dataset_split(valid_labels)\n",
    "    test_neg, test_pos = counts_from_dataset_split(test_labels)\n",
    "\n",
    "    print(\"\\n=== Class balance per split ===\")\n",
    "    show_dataset_split_summary(\"train\", train_neg, train_pos)\n",
    "    show_dataset_split_summary(\"valid\", valid_neg, valid_pos)\n",
    "    show_dataset_split_summary(\"test \",  test_neg,  test_pos)\n",
    "\n",
    "    # Visualization\n",
    "    split_titles = [\"Train\", \"Valid\", \"Test\"]\n",
    "    negative_counts = [train_neg, valid_neg, test_neg]\n",
    "    positive_counts = [train_pos, valid_pos, test_pos]\n",
    "    totals_per_split = [n + p for n, p in zip(negative_counts, positive_counts)]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4), constrained_layout=True)\n",
    "    for ax, title, n0, n1, N in zip(axes, split_titles, negative_counts, positive_counts, totals_per_split):\n",
    "        ax.bar([\"Negative (0)\", \"Positive (1)\"], [n0, n1])\n",
    "        pos_pct = (n1 / N * 100) if N else 0.0\n",
    "        ax.set_title(f\"{title}\\nN={N}, pos={pos_pct:.1f}%\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.grid(axis=\"y\", alpha=0.2)\n",
    "\n",
    "    fig.suptitle(f\"Class balance by split — label: '{BINARY_LABEL_COL}'\")\n",
    "    fig.savefig(save_png, dpi=200, bbox_inches=\"tight\")\n",
    "    print(f\"\\nSaved chart → {save_png}\")\n",
    "\n",
    "    # Inverted weights for Keras (train split only)\n",
    "    train_total = train_neg + train_pos\n",
    "    class_weight = {\n",
    "        0: train_total / (2 * train_neg),\n",
    "        1: train_total / (2 * train_pos),\n",
    "    }\n",
    "\n",
    "    cw0, cw1 = class_weight[0], class_weight[1]\n",
    "    print(f\"Inverse weighting for imbalance: class_weight={{0: {cw0:.3f}, 1: {cw1:.3f}}}\")\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c02128-9e68-422e-bc51-2bb44b744bf2",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598e9d9-afe1-4b9d-ab7b-964f0876727d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.1. Crop square and resize images to (384x384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0dc27c-e593-4e98-bf91-14fee9e2afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_square_resize_image(\n",
    "    img_bgr: np.ndarray,\n",
    "    out_size: int = 384,\n",
    "    black_delta: int = 5,\n",
    "    margin_frac: float = 0.03,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Remove near-black borders using a dynamic threshold, keep the largest\n",
    "    content region, pad to a square with the crop border's median color,\n",
    "    then resize to `out_size`. Returns BGR uint8.\n",
    "    \"\"\"\n",
    "    # Grayscale for thresholding\n",
    "    # Treba nam samo intenzitet izmedju skroz crno i ocne slike\n",
    "    # Cheaper and sufficient\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    gray = cv.cvtColor(img_bgr, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Dynamic threshold from the image border\n",
    "    border = np.concatenate([gray[0, :], gray[-1, :], gray[:, 0], gray[:, -1]])\n",
    "    threshold = int(max(10, np.median(border) + black_delta))\n",
    "\n",
    "    # Binary mask (content = 255)\n",
    "    # Sve svetlije od okoline se uzima kao content\n",
    "    mask = (gray > threshold).astype(np.uint8) * 255\n",
    "\n",
    "    # Morphological closing to seal thin gaps on the rim\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (7, 7))\n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # Largest connected component (the retina)\n",
    "    num_labels, labels, stats, _ = cv.connectedComponentsWithStats(mask, connectivity=8)\n",
    "    if num_labels <= 1:\n",
    "        # Fallback: nothing detected → just resize\n",
    "        print(\"Error when trying to process image, no values recieved!\")\n",
    "        return cv.resize(img_bgr, (out_size, out_size), interpolation=cv.INTER_AREA)\n",
    "\n",
    "    largest_id = 1 + np.argmax(stats[1:, cv.CC_STAT_AREA])\n",
    "    x, y, bw, bh, _ = stats[largest_id]\n",
    "\n",
    "    # Expand slightly to avoid clipping the rim\n",
    "    # Dodavanje malog paddinga da ne bi doslo do isecanja ocne slike\n",
    "    pad_h = int(bh * margin_frac)\n",
    "    pad_w = int(bw * margin_frac)\n",
    "    x0 = max(0, x - pad_w)\n",
    "    y0 = max(0, y - pad_h)\n",
    "    x1 = min(w, x + bw + pad_w) \n",
    "    y1 = min(h, y + bh + pad_h)\n",
    "    \n",
    "    crop = img_bgr[y0:y1, x0:x1, :]\n",
    "    ch, cw = crop.shape[:2]\n",
    "\n",
    "    # Square-pad (no stretching)\n",
    "    side = max(ch, cw)\n",
    "    top = (side - ch) // 2\n",
    "    bottom = side - ch - top\n",
    "    left = (side - cw) // 2\n",
    "    right = side - cw - left\n",
    "\n",
    "    # Pad color = median of the crop border (neutral)\n",
    "    border_pixels = np.vstack([crop[0, :, :], crop[-1, :, :], crop[:, 0, :], crop[:, -1, :]])\n",
    "    pad_color = np.median(border_pixels.reshape(-1, 3), axis=0).astype(np.uint8).tolist()\n",
    "    padded = cv.copyMakeBorder(\n",
    "        crop, top, bottom, left, right, borderType=cv.BORDER_CONSTANT, value=pad_color\n",
    "    )\n",
    "    # Final resize\n",
    "    out = cv.resize(padded, (out_size, out_size), interpolation=cv.INTER_AREA)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14af973-f896-4331-bd45-0879993a83aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.2. Process and save resized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce068acf-4b62-443c-969a-f7ca764edc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_resized_images_from_dataset_split(\n",
    "    input_dir,\n",
    "    output_dir,\n",
    "    out_size: int = 384,\n",
    "    workers: int | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Read all images in `input_dir`, trim borders + square-pad + resize,\n",
    "    and write PNGs to `output_dir`.\n",
    "    - Accepts: .jpg/.jpeg/.png (case-insensitive)\n",
    "    - Output: lossless PNG with moderate compression (level 6)\n",
    "    - Parallelism: ThreadPoolExecutor (set workers=0 or 1 to run sequentially)\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Collect inputs (deterministic order helps reproducibility)\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\"}\n",
    "    paths = sorted(p for p in input_dir.iterdir() if p.is_file() and p.suffix.lower() in exts)\n",
    "    if not paths:\n",
    "        print(f\"[process_dir] No images found in {input_dir}\")\n",
    "        return\n",
    "\n",
    "    # 2) Decide worker count (simple, CPU-friendly default)\n",
    "    if workers is None:\n",
    "        workers = min(8, os.cpu_count() or 2)\n",
    "\n",
    "    def _process_one(p: Path):\n",
    "        # Read as 3-channel color for consistency with Keras preprocessors\n",
    "        img = cv.imread(str(p), cv.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            # keep it simple—skip unreadable files without extra handling\n",
    "            return\n",
    "        out = crop_square_resize_image(img, out_size=out_size)\n",
    "\n",
    "        out_path = output_dir / f\"{p.stem}.png\"\n",
    "        # PNG is lossless; compression=6 gives good size without being slow\n",
    "        cv.imwrite(str(out_path), out, [int(cv.IMWRITE_PNG_COMPRESSION), 6])\n",
    "\n",
    "    # 3) Process (parallel if workers>1)\n",
    "    if workers and workers > 1:\n",
    "        from concurrent.futures import ThreadPoolExecutor\n",
    "        with ThreadPoolExecutor(max_workers=workers) as ex:\n",
    "            list(ex.map(_process_one, paths))\n",
    "    else:\n",
    "        for p in paths:\n",
    "            _process_one(p)\n",
    "\n",
    "    print(f\"[process_dir] Wrote {len(paths)} images → {output_dir}  (size={out_size}×{out_size})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63edce55-cbf1-498f-8b97-8a859ea0fa38",
   "metadata": {},
   "source": [
    "## 2. Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ef52b-58a9-42df-8cca-d4750926eb6a",
   "metadata": {},
   "source": [
    "### 2.1. Reading file paths and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b8052-7c97-4ff4-aad0-7afc57a5dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.setNumThreads(0)\n",
    "\n",
    "# Utility for removing extensions to read label for the given image filename\n",
    "def normalize_fname(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    # remove one trailing extension\n",
    "    if \".\" in s:\n",
    "        s = s[: s.rfind(\".\")]\n",
    "    return s\n",
    "    \n",
    "def load_samples_from_csv(\n",
    "    csv_path: str | Path,\n",
    "    images_dir: str | Path,\n",
    "    image_col: str = \"Image name\",\n",
    "    label_col: str = \"Risk of macular edema\",\n",
    "    seed: Optional[int] = 123,\n",
    ") -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Return a pre-shuffled list of (png_path, label) pairs, matching CSV names by stem.\n",
    "    Assumes preprocessed images are stored as <stem>.png in images_dir.\n",
    "    \"\"\"\n",
    "    images_dir = Path(images_dir)\n",
    "    samples: List[Tuple[str, int]] = []\n",
    "\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            stem = normalize_fname(row[image_col])\n",
    "            png = images_dir / f\"{stem}.png\"\n",
    "            if png.exists():\n",
    "                samples.append((str(png), int(row[label_col])))\n",
    "\n",
    "    if not samples:\n",
    "        raise FileNotFoundError(f\"No matching .png files for {csv_path} in {images_dir}\")\n",
    "\n",
    "    # Pre-shuffle list of zipped file paths and labels \n",
    "    if seed is not None:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.permutation(len(samples))\n",
    "        samples = [samples[i] for i in idx]\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0d8a0e-71bf-4691-80a7-8cd1b5e00569",
   "metadata": {},
   "source": [
    "### 2.2. Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573b027-bf53-4a13-890a-7c0458ebf381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_data_gen(fill_value=0.03) -> tf.keras.preprocessing.image.ImageDataGenerator:\n",
    "    return tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        zoom_range=[1.0, 1.15],\n",
    "        fill_mode=\"constant\",\n",
    "        cval=fill_value,\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "img_datagen = get_img_data_gen()\n",
    "\n",
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img.set_shape([image_size, image_size, 3])\n",
    "    return img, label\n",
    "\n",
    "def idg_augment_tf(img, label):\n",
    "    def _aug(np_img):\n",
    "        x = img_datagen.random_transform(np_img)\n",
    "        return x.astype(np.float32)\n",
    "    img = tf.numpy_function(_aug, [img], tf.float32)\n",
    "    img.set_shape([image_size, image_size, 3])\n",
    "    return img, label\n",
    "\n",
    "def create_dataset_from_split(samples, augment, shuffle):\n",
    "    paths = tf.constant([p for p, _ in samples])\n",
    "    labels = tf.constant([l for _, l in samples], dtype=tf.int32)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(samples), seed=42, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if augment:\n",
    "        ds = ds.map(idg_augment_tf, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c5b01-9fd2-4b95-b6bd-9a0f1a637191",
   "metadata": {},
   "source": [
    "## 3. Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708aca1-64d6-457f-909e-0b62993a2723",
   "metadata": {},
   "source": [
    "### 3.1. Hyperparameters and Train Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3805665-52fe-4cd8-b9e7-5bce9fba50f0",
   "metadata": {},
   "source": [
    "#### 3.1.1. Inverse weight and class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f723a0a-8b7c-4e76-803d-1749745945c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = show_class_balance(\n",
    "    train_labels=train_labels,\n",
    "    valid_labels=valid_labels,\n",
    "    test_labels=test_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200fe20f-2bec-4026-9aaf-d6a9872cd8a2",
   "metadata": {},
   "source": [
    "#### 3.1.2. Experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4602a1b-e6fd-4348-9a84-4bfc7ceb13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = \"ViTBase32\"\n",
    "experiment_no = 6\n",
    "\n",
    "image_size = 384\n",
    "batch_size = 16\n",
    "\n",
    "cnn_architectures = {'ResNet50', 'EfficientNetV2S', 'ConvNeXtTiny', 'EfficientNetB4'}\n",
    "\n",
    "curr_folder = f\"deep_learning/working/experiments/{architecture}_00{experiment_no} - AUC\"\n",
    "if not os.path.exists(curr_folder):\n",
    "    os.mkdir(curr_folder)\n",
    "\n",
    "experiments_csv_path = os.path.join(\"deep_learning/working/experiments\", \"all_experiments.csv\")\n",
    "model_path = os.path.join(curr_folder, 'model.keras')\n",
    "metadata_path = os.path.join(curr_folder, 'model.json')\n",
    "log_path = os.path.join(curr_folder, 'log.csv')\n",
    "log_warmup_path = os.path.join(curr_folder, 'log_warmup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d92a6-062b-4b77-b2f5-8c18127c5c05",
   "metadata": {},
   "source": [
    "#### 3.1.3. Hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e08ac3-395c-4d47-8418-055ddcd20dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_optimizer(name: str, lr, wd):\n",
    "    if name == \"Adam\":\n",
    "        return tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    if name == \"AdamW\":\n",
    "        return tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
    "\n",
    "init_lr = 1e-3\n",
    "weight_decay = 0 \n",
    "optimizer_name = \"AdamW\"\n",
    "optimizer = select_optimizer(name=optimizer_name, lr=init_lr, wd=weight_decay)\n",
    "# val_monitor = ('val_binary_accuracy', 'max')\n",
    "val_monitor = ('val_auc', 'max')\n",
    "epochs = 30\n",
    "epochs_warmup = 5\n",
    "reduce_lr_patience = 5\n",
    "early_stopping_patience = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd7a06-5a48-416a-89bf-cdd61091c818",
   "metadata": {},
   "source": [
    "#### 3.1.4. Model fit callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dadefb-59b0-4ad2-954c-3feae8ee3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = tf.keras.callbacks.CSVLogger(log_path, separator=',', append=False)\n",
    "csv_logger_warmup = tf.keras.callbacks.CSVLogger(log_warmup_path, separator=',', append=False)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    factor=0.1, \n",
    "    patience=reduce_lr_patience,\n",
    "    monitor=val_monitor[0], \n",
    "    mode=val_monitor[1]\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=early_stopping_patience, \n",
    "    verbose=1,                               \n",
    "    restore_best_weights=True,\n",
    "    monitor=val_monitor[0], \n",
    "    mode=val_monitor[1]\n",
    ")\n",
    "\n",
    "checkpoint_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path, \n",
    "    monitor=val_monitor[0], \n",
    "    mode=val_monitor[1], \n",
    "    verbose=1, \n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcfd751-7b42-4f7d-98ed-c5dc3d0dc319",
   "metadata": {},
   "source": [
    "### 3.2. Architecture selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b956e203-264b-4e0d-a0e3-23b1ec788abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if architecture == 'ResNet50':\n",
    "    preprocess_input = tf.keras.applications.resnet.preprocess_input\n",
    "    encoder = tf.keras.applications.ResNet50\n",
    "elif architecture == 'EfficientNetV2S':\n",
    "    preprocess_input = tf.keras.applications.efficientnet_v2.preprocess_input\n",
    "    encoder = tf.keras.applications.EfficientNetV2S\n",
    "elif architecture == 'ConvNeXtTiny':\n",
    "    preprocess_input = tf.keras.applications.convnext.preprocess_input\n",
    "    encoder = tf.keras.applications.ConvNeXtTiny\n",
    "elif architecture == 'EfficientNetB4':\n",
    "    preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "    encoder = tf.keras.applications.EfficientNetB4\n",
    "elif architecture == 'ViTBase16':\n",
    "    backbone = keras_hub.models.Backbone.from_preset(\n",
    "        \"vit_base_patch16_384_imagenet\"\n",
    "    )\n",
    "    preprocessor = keras_hub.models.ViTImageClassifierPreprocessor.from_preset(\n",
    "        \"vit_base_patch16_384_imagenet\"\n",
    "    )\n",
    "elif architecture == 'ViTBase32':\n",
    "    backbone = keras_hub.models.Backbone.from_preset(\n",
    "        \"vit_base_patch32_384_imagenet\"\n",
    "    )\n",
    "    preprocessor = keras_hub.models.ViTImageClassifierPreprocessor.from_preset(\n",
    "        \"vit_base_patch32_384_imagenet\"\n",
    "    )\n",
    "# elif architecture == 'DeiTBase16':\n",
    "#     backbone = keras_hub.models.DeiTBackbone.from_preset(\n",
    "#         \"deit_base_distilled_patch16_384_imagenet\"\n",
    "#     )\n",
    "#     preprocessor = keras_hub.models.DeiTImageClassifierPreprocessor.from_preset(\n",
    "#         \"deit_base_distilled_patch16_384_imagenet\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff56df5a-7d68-4bf5-8ccd-2b6d60c73054",
   "metadata": {},
   "source": [
    "### 3.3. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb927a4-6428-4b72-9e80-48b9ac36a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier_model(trainable_encoder):\n",
    "    in_shp = (image_size, image_size, 3)\n",
    "    x = tf.keras.layers.Input(shape=in_shp, name='input')\n",
    "    z = x\n",
    "    \n",
    "    if architecture not in cnn_architectures:\n",
    "        # Freeze the entire backbone\n",
    "        backbone.trainable = trainable_encoder\n",
    "        z = preprocessor(z)\n",
    "        y = backbone(z)\n",
    "        y = tf.keras.layers.Lambda(lambda t: t[:, 0, :], name=\"cls_token\")(y)\n",
    "        \n",
    "    else:\n",
    "        y = tf.keras.layers.Lambda(preprocess_input, name=\"preproc\")(z)\n",
    "        cnn_backbone = encoder(include_top=False, weights='imagenet', input_shape=in_shp, input_tensor=y, pooling='avg', classes=2)\n",
    "        if not trainable_encoder:\n",
    "            for layer in cnn_backbone.layers:\n",
    "                layer.trainable = False\n",
    "        \n",
    "        y = cnn_backbone.output\n",
    "        \n",
    "    y = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(y)\n",
    "    model = tf.keras.models.Model(inputs=x, outputs=y, name=f\"{architecture}_binclass\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be06d94-da6e-4165-aa47-5b7efbfdcd04",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bde5cf-115a-493c-996d-0971f6662084",
   "metadata": {},
   "source": [
    "### 4.0. Preprocessing and loading samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4084c-bf75-46f2-8f60-f959cef99077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Called only once on first startup, comment after that to avoid unesscesary processing!\n",
    "# save_resized_images_from_dataset_split(os.path.join(train_path, \"images\"), \"working/preprocessed/train/images_resized\", out_size=image_size, workers=8)\n",
    "# save_resized_images_from_dataset_split(os.path.join(valid_path, \"images\"), \"working/preprocessed/valid/images_resized\", out_size=image_size, workers=8)\n",
    "# save_resized_images_from_dataset_split(os.path.join(test_path, \"images\"),  \"working/preprocessed/test/images_resized\",  out_size=image_size, workers=8)\n",
    "\n",
    "# Used for creating datasets for train and evaluation\n",
    "train_samples = load_samples_from_csv(train_labels, \"deep_learning/working/preprocessed/train/images_resized\")\n",
    "valid_samples = load_samples_from_csv(valid_labels, \"deep_learning/working/preprocessed/valid/images_resized\")\n",
    "test_samples = load_samples_from_csv(test_labels, \"deep_learning/working/preprocessed/test/images_resized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb775f-d7a0-4824-a43b-838077d95080",
   "metadata": {},
   "source": [
    "### 4.1. Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c8005-10f1-4524-adc7-4f2cd2995067",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_classifier_model(False)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=[tf.keras.metrics.binary_accuracy, tf.keras.metrics.AUC(name=\"auc\", curve=\"ROC\", num_thresholds=200)],\n",
    "    jit_compile=False,\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb0dc04-d86b-4498-abdd-2f80642b53fe",
   "metadata": {},
   "source": [
    "### 4.2. Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aab395-2112-47cf-ac16-181d50f5e278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (path, label)\n",
    "train_dataset = create_dataset_from_split(train_samples, augment=True, shuffle=True)\n",
    "valid_dataset = create_dataset_from_split(valid_samples, augment=False, shuffle=False)\n",
    "\n",
    "history_warmup = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs_warmup,\n",
    "    callbacks=[csv_logger_warmup, reduce_lr, checkpoint_best],\n",
    "    class_weight=class_weight,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8e274-6c8b-4da5-a43e-423493916f08",
   "metadata": {},
   "source": [
    "### 4.3. Full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45eb227-fb22-4104-a01f-ee8f9aea3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "fine_tune_lr = 1e-5\n",
    "weight_decay = 1e-4 if optimizer_name == 'AdamW' else 0\n",
    "model.compile(optimizer=select_optimizer(name=optimizer_name, lr=fine_tune_lr, wd=weight_decay),\n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics=[tf.keras.metrics.binary_accuracy, tf.keras.metrics.AUC(name=\"auc\", curve=\"ROC\", num_thresholds=200)])\n",
    "\n",
    "history_full = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[csv_logger, reduce_lr, early_stopping, checkpoint_best],\n",
    "    class_weight=class_weight,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03760cec-92c5-4892-bdbd-4163b3901baf",
   "metadata": {},
   "source": [
    "### 4.4. Save training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d238ca78-51d6-4ee8-9531-5bf1b80ee6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist, metric, title, outfile):\n",
    "    plt.clf()\n",
    "    if metric in hist.history:\n",
    "        plt.plot(hist.history[metric], label=f\"train {metric}\")\n",
    "    if f\"val_{metric}\" in hist.history:\n",
    "        plt.plot(hist.history[f'val_{metric}'], label=f\"val {metric}\")\n",
    "    plt.title(title); plt.xlabel(\"Epoch\"); plt.ylabel(metric); plt.grid(True, alpha=.3); plt.legend()\n",
    "    plt.savefig(os.path.join(curr_folder, outfile), dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# Warmup\n",
    "plot_hist(history_warmup, \"binary_accuracy\", \"Binary Accuracy (warmup)\", \"warmup_accuracy.png\")\n",
    "plot_hist(history_warmup, \"loss\", \"Loss (warmup)\", \"warmup_loss.png\")\n",
    "plot_hist(history_warmup, \"auc\", \"AUC (warmup)\", \"warmup_auc.png\")\n",
    "\n",
    "# Full training\n",
    "plot_hist(history_full, \"binary_accuracy\", \"Binary Accuracy (full)\", \"full_accuracy.png\")\n",
    "plot_hist(history_full, \"loss\", \"Loss (full)\", \"full_loss.png\")\n",
    "plot_hist(history_full, \"auc\", \"AUC (full)\", \"full_auc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8175880-2d8f-44a1-8ab6-cc7751458f74",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2d978-0c33-45a0-a463-7ee997f1dd47",
   "metadata": {},
   "source": [
    "### 5.0. Evaluation Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd231467-37ee-4497-a58d-f78a9254a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    roc_curve, roc_auc_score, \n",
    "    precision_recall_curve, average_precision_score, \n",
    "    confusion_matrix, ConfusionMatrixDisplay, \n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b99692-0d28-486a-8672-0d49eb87eaa6",
   "metadata": {},
   "source": [
    "### 5.1. Predict and Evaluate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b45b3-838b-4daa-9840-022835c8af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels_and_scores(eval_dataset):\n",
    "    \"\"\"\n",
    "    Run model.predict on a dataset (no augmentation) and return:\n",
    "    - y_true: 1D int array of shape [N]\n",
    "    - y_pred: 1D float array of shape [N], sigmoid probabilities in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = np.concatenate([y.numpy().ravel() for _, y in eval_dataset]).astype(np.int32)\n",
    "    y_pred = np.squeeze(model.predict(eval_dataset, verbose=0), axis=-1).astype(np.float32)\n",
    "    return y_true, y_pred\n",
    "\n",
    "def evaluate_split(y_true, y_pred, tau=0.5):\n",
    "    y_true = np.asarray(y_true).astype(int).ravel()\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float32).ravel()\n",
    "\n",
    "    pred_labels = (y_pred >= float(tau)).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, pred_labels, labels=[0,1])\n",
    "    metrics = {\n",
    "        \"accuracy\":  accuracy_score(y_true, pred_labels),\n",
    "        \"precision\": precision_score(y_true, pred_labels, zero_division=0),\n",
    "        \"recall\":    recall_score(y_true, pred_labels),\n",
    "        \"f1\":        f1_score(y_true, pred_labels),\n",
    "        \"auroc\":     roc_auc_score(y_true, y_pred),\n",
    "        \"auprc\":     average_precision_score(y_true, y_pred),\n",
    "        \"cm\":        cm,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174bee5-e03c-4a7c-a5b7-a96dbfad2626",
   "metadata": {},
   "source": [
    "### 5.2. Save Experiment and Evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe25a1c-44c0-429a-a1cd-b24a74a87e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_pct(x, nd=2):\n",
    "    \"\"\"Format as percentage string with nd decimals (e.g., '91.23%').\"\"\"\n",
    "    v = float(np.asarray(x))\n",
    "    if abs(v) < 1e-12:\n",
    "        v = 0.0\n",
    "    return f\"{v * 100:.{nd}f}%\"\n",
    "\n",
    "def rnd(x, nd=4):\n",
    "    \"\"\"Round to nd decimals and return a Python float (good for CSV).\"\"\"\n",
    "    v = np.round(np.asarray(x, dtype=np.float64), nd)\n",
    "    return float(v) if np.ndim(v) == 0 else v.tolist()\n",
    "\n",
    "def save_roc_curve(y_true, y_pred, title, out_path_png):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"AUROC={auroc:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], \"--\", lw=1, color=\"gray\")\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title); plt.grid(True, alpha=.3); plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(out_path_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def save_confusion_matrix_results(\n",
    "    cm, \n",
    "    class_names=(\"negative\",\"positive\"),\n",
    "    out_counts_png=None, \n",
    "    out_rowperc_png=None\n",
    "):\n",
    "    \"\"\"\n",
    "    1) counts with 'Misclassified X of N'\n",
    "    2) row-normalized % with 'Classification accuracy Y%'\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    total = cm.sum()\n",
    "    acc = (tn + tp) / total\n",
    "    miscls = total - (tn + tp)\n",
    "\n",
    "    if out_counts_png:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8.5))\n",
    "        im = ax.imshow(cm, cmap=\"Blues\")\n",
    "        ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "        ax.set_xticklabels([\"negative\",\"positive\"])\n",
    "        ax.set_yticklabels([\"negative\",\"positive\"])\n",
    "        ax.set_xlabel(\"Predicted label\"); ax.set_ylabel(\"True label\")\n",
    "        title = f\"Misclassified {miscls} out of {total} case studies\"\n",
    "        ax.set_title(title)\n",
    "        for (i,j), v in np.ndenumerate(cm):\n",
    "            tag = (\"TN\",\"FP\",\"FN\",\"TP\")[(i*2)+j]\n",
    "            ax.text(j, i, f\"{v}\\n{tag}\", va=\"center\", ha=\"center\", color=\"black\")\n",
    "        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.ax.set_ylabel(\"count\", rotation=90, va=\"bottom\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_counts_png, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    if out_rowperc_png:\n",
    "        row_sum = cm.sum(axis=1, keepdims=True).clip(min=1)\n",
    "        rowperc = (cm / row_sum) * 100.0\n",
    "        fig, ax = plt.subplots(figsize=(10, 8.5))\n",
    "        im = ax.imshow(rowperc, cmap=\"Blues\", vmin=0, vmax=100)\n",
    "        ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "        ax.set_xticklabels([\"negative\",\"positive\"])\n",
    "        ax.set_yticklabels([\"negative\",\"positive\"])\n",
    "        ax.set_xlabel(\"Predicted label\"); ax.set_ylabel(\"True label\")\n",
    "        title = f\"Classification accuracy {as_pct(acc)}\"\n",
    "        ax.set_title(title)\n",
    "        for (i,j), v in np.ndenumerate(rowperc):\n",
    "            tag = (\"TN\",\"FP\",\"FN\",\"TP\")[(i*2)+j]\n",
    "            ax.text(j, i, f\"{v:.1f}%\\n{tag}\", va=\"center\", ha=\"center\", color=\"black\")\n",
    "        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.ax.set_ylabel(\"% within true class\", rotation=90, va=\"bottom\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_rowperc_png, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "def append_row_to_experiments_csv(csv_path, row_dict, column_order):\n",
    "    \"\"\"\n",
    "    Append one experiment row to CSV. If file doesn't exist, write header first.\n",
    "    `row_dict` keys must match `column_order`.\n",
    "    \"\"\"\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=column_order)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e512c60-29a5-42dc-bd88-ce63b81a36e6",
   "metadata": {},
   "source": [
    "### 5.3. Create datasets for evaluation and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076899b-09ad-4137-84c5-857dbe5a0591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(filepath=model_path, compile=False, safe_mode=False)\n",
    "\n",
    "eval_ds_train = create_dataset_from_split(train_samples, augment=False, shuffle=False)\n",
    "eval_ds_valid = create_dataset_from_split(valid_samples, augment=False, shuffle=False)\n",
    "eval_ds_test  = create_dataset_from_split(test_samples,  augment=False, shuffle=False)\n",
    "\n",
    "y_true_valid, y_pred_valid = predict_labels_and_scores(eval_ds_valid)\n",
    "y_true_test, y_pred_test = predict_labels_and_scores(eval_ds_test)\n",
    "y_true_train, y_pred_train = predict_labels_and_scores(eval_ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce755136-ad4c-40d8-9829-452e853feb76",
   "metadata": {},
   "source": [
    "### 5.4. Get evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93d83b-b29a-4900-8c65-fe4f0cbf26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metrics = evaluate_split(y_true=y_true_valid, y_pred=y_pred_valid)\n",
    "test_metrics = evaluate_split(y_true=y_true_test, y_pred=y_pred_test)\n",
    "train_metrics = evaluate_split(y_true=y_true_train, y_pred=y_pred_train)\n",
    "\n",
    "def brief(m):\n",
    "    return (f\"acc={m['accuracy']:.4f}  auroc={m['auroc']:.4f}  auprc={m['auprc']:.4f}  \"\n",
    "            f\"prec={m['precision']:.4f}  rec={m['recall']:.4f}  f1={m['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nVALID @ τ=0.5:\", brief(valid_metrics))\n",
    "print(\"TEST @ τ=0.5:\", brief(test_metrics))\n",
    "print(\"TRAIN @ τ=0.5:\", brief(train_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83f7ac-1095-46a2-bbc5-f7bffea5f2ce",
   "metadata": {},
   "source": [
    "### 5.5. Save evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8b545-9f4f-47d0-a962-f96b1172bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_roc_curve(y_true_valid, y_pred_valid, \"Validation ROC\", os.path.join(curr_folder, \"roc_val.png\"))\n",
    "save_roc_curve(y_true_test, y_pred_test, \"Test ROC\", os.path.join(curr_folder, \"roc_test.png\"))\n",
    "\n",
    "save_confusion_matrix_results(\n",
    "    valid_metrics[\"cm\"],\n",
    "    out_counts_png=os.path.join(curr_folder, \"cm_val_counts.png\"),\n",
    "    out_rowperc_png=os.path.join(curr_folder, \"cm_val_rowperc.png\"),\n",
    ")\n",
    "\n",
    "save_confusion_matrix_results(\n",
    "    test_metrics[\"cm\"],\n",
    "    out_counts_png=os.path.join(curr_folder, \"cm_test_counts.png\"),\n",
    "    out_rowperc_png=os.path.join(curr_folder, \"cm_test_rowperc.png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c676a687-97bf-4adc-a17b-0bb0ccd5dacb",
   "metadata": {},
   "source": [
    "### 5.6. Save experiment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4496dc-d674-4046-9df9-97c1224734fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup_freeze_policy   = \"only output trainable\"\n",
    "# finetune_freeze_policy = \"all layers trainable, BN frozen\"\n",
    "has_bn = architecture in {\"ResNet50\", \"EfficientNetV2S\", \"EfficientNetB4\"}\n",
    "# bn_frozen_warmup   = \"yes\" if has_bn else \"n/a\"\n",
    "# bn_frozen_finetune = \"yes\"\n",
    "\n",
    "csv_row = {\n",
    "    # run context\n",
    "    \"experiment_no\": experiment_no,\n",
    "    \"architecture\": architecture,\n",
    "    \"image_size\": image_size,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"init_lr\": init_lr,\n",
    "    \"finetune_lr\": fine_tune_lr,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"optimizer\": optimizer_name,\n",
    "    # \"warmup_freeze\": warmup_freeze_policy,\n",
    "    # \"finetune_freeze\": finetune_freeze_policy,\n",
    "    \"has_bn\": \"yes\" if has_bn else \"no\",\n",
    "    # \"bn_frozen_warmup\": bn_frozen_warmup,\n",
    "    # \"bn_frozen_finetune\": bn_frozen_finetune,\n",
    "\n",
    "    # train/val (only AUC + accuracy for the sheet)\n",
    "    \"train_acc\": as_pct(train_metrics[\"accuracy\"]),\n",
    "    \"train_auroc\": rnd(train_metrics[\"auroc\"], 4),\n",
    "    \"val_acc\": as_pct(valid_metrics[\"accuracy\"]),\n",
    "    \"val_auroc\": rnd(valid_metrics[\"auroc\"], 4),\n",
    "\n",
    "    # test (full set; rounded/percent where it helps)\n",
    "    \"test_acc\":  as_pct(test_metrics[\"accuracy\"]),\n",
    "    \"test_auroc\": rnd(test_metrics[\"auroc\"], 4),\n",
    "    \"test_auprc\": rnd(test_metrics[\"auprc\"], 4),\n",
    "    \"test_prec\": as_pct(test_metrics[\"precision\"]),\n",
    "    \"test_rec\":  as_pct(test_metrics[\"recall\"]),\n",
    "    \"test_f1\":   as_pct(test_metrics[\"f1\"]),\n",
    "    \"tau_used\": 0.5,\n",
    "}\n",
    "\n",
    "csv_columns = [\n",
    "    \"experiment_no\",\"architecture\",\"image_size\",\"batch_size\",\"init_lr\",\"finetune_lr\",\"weight_decay\",\"optimizer\",\"has_bn\",\n",
    "    \"train_acc\",\"train_auroc\",\"val_acc\",\"val_auroc\",\n",
    "    \"test_acc\",\"test_auroc\",\"test_auprc\",\"test_prec\",\"test_rec\",\"test_f1\",\"tau_used\",\n",
    "]\n",
    "\n",
    "append_row_to_experiments_csv(experiments_csv_path, csv_row, csv_columns)\n",
    "print(f\"\\nAppended metrics → {experiments_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0675d620-c287-4757-b963-da93d4a55b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    roc_curve, roc_auc_score, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51554ff-7b7f-46b0-b5b1-9968cec4982a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5.2. Predict, threshold and evaluation on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef32de66-ac63-4094-a96c-d5399e12a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels_and_scores(eval_dataset):\n",
    "    \"\"\"\n",
    "    Run model.predict on a dataset (no augmentation) and return:\n",
    "    - y_true: 1D int array of shape [N]\n",
    "    - y_pred: 1D float array of shape [N], sigmoid probabilities in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = np.concatenate([y.numpy().ravel() for _, y in eval_dataset]).astype(np.int32)\n",
    "    y_pred = np.squeeze(model.predict(eval_dataset, verbose=0), axis=-1).astype(np.float32)\n",
    "    return y_true, y_pred\n",
    "\n",
    "def get_threshold_for_sensitivity(y_true, y_pred, target_sens=0.90):\n",
    "    fp_rate, tp_rate, threshold = roc_curve(y_true, y_pred)\n",
    "    idx = np.where(tp_rate >= target_sens)[0]\n",
    "    tau_sens = float(threshold[idx[0]]) if idx.size else 1.0\n",
    "    return tau_sens, (fp_rate, tp_rate, threshold)\n",
    "\n",
    "def evaluate_split_at_threshold(y_true, y_pred, tau):\n",
    "    \"\"\"\n",
    "    Compute standard metrics at a fixed threshold τ:\n",
    "    - accuracy, precision, recall, F1\n",
    "    - AUROC (threshold-free), AUPRC (threshold-free)\n",
    "    - confusion_matrix (2x2 for [neg,pos])\n",
    "    Returns a metrics dict.\n",
    "    \"\"\"\n",
    " \n",
    "    y_true = np.asarray(y_true).astype(int).ravel()\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float32).ravel()\n",
    "    \n",
    "    pred_labels = (y_pred >= float(tau)).astype(int)\n",
    "    cm = confusion_matrix(y_true, pred_labels, labels=[0, 1])\n",
    "    metrics = {\n",
    "        \"accuracy\":  accuracy_score(y_true, pred_labels),\n",
    "        \"precision\": precision_score(y_true, pred_labels, zero_division=0),\n",
    "        \"recall\":    recall_score(y_true, pred_labels),\n",
    "        \"f1\":        f1_score(y_true, pred_labels),\n",
    "        \"auroc\":     roc_auc_score(y_true, y_pred),\n",
    "        \"auprc\":     average_precision_score(y_true, y_pred),\n",
    "        \"cm\":        cm,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac6932-b100-4af7-b0ff-ea135bc8b437",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5.3. Helper methods for plotting and saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd6ae6-3995-4220-8115-ef4beff30323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_confusion_matrix(cm, title, out_path_png):\n",
    "    \"\"\"Render and save a confusion matrix figure to PNG.\"\"\"\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=[0, 1])\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    disp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=False)\n",
    "    ax.set_title(title)\n",
    "    fig.savefig(out_path_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_roc_curve(true_labels, pred_scores, title, out_path_png):\n",
    "    \"\"\"Render and save an ROC curve figure to PNG.\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(true_labels, pred_scores)\n",
    "    auroc = roc_auc_score(true_labels, pred_scores)\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"AUROC={auroc:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], \"--\", lw=1, color=\"gray\")\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title); plt.grid(True, alpha=.3); plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(out_path_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def append_row_to_experiments_csv(csv_path, row_dict, column_order):\n",
    "    \"\"\"\n",
    "    Append one experiment row to CSV. If file doesn't exist, write header first.\n",
    "    `row_dict` keys must match `column_order`.\n",
    "    \"\"\"\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=column_order)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be31ad3-d3b4-433a-baf9-086a51fad7eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5.4. Full Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5475fd-ae21-4950-8cac-671fdd78473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = load_samples_from_csv(test_labels, \"working/preprocessed/test/images_resized\")\n",
    "\n",
    "eval_ds_train = create_dataset_from_split(train_samples, augment=False, shuffle=False)\n",
    "eval_ds_valid = create_dataset_from_split(valid_samples, augment=False, shuffle=False)\n",
    "eval_ds_test  = create_dataset_from_split(test_samples,  augment=False, shuffle=False)\n",
    "\n",
    "labels_valid, scores_valid = predict_labels_and_scores(eval_ds_valid)\n",
    "labels_test, scores_test  = predict_labels_and_scores(eval_ds_test)\n",
    "labels_train, scores_train = predict_labels_and_scores(eval_ds_train)\n",
    "\n",
    "target_sensitivity = 0.90\n",
    "tau_target_sensitivity, (fpr_v, tpr_v, thr_v) = get_threshold_for_sensitivity(\n",
    "    labels_valid, scores_valid, target_sensitivity\n",
    ")\n",
    "print(f\"[Operating τ] First TPR ≥ {target_sensitivity:.2f} → τ = {tau_target_sensitivity:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429d578-4cd2-40a8-8dac-e80344aa5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_valid = evaluate_split_at_threshold(labels_valid, scores_valid, tau_target_sensitivity)\n",
    "metrics_test  = evaluate_split_at_threshold(labels_test,  scores_test,  tau_target_sensitivity)\n",
    "metrics_train = evaluate_split_at_threshold(labels_train, scores_train, tau_target_sensitivity)\n",
    "\n",
    "save_roc_curve(labels_valid, scores_valid, \"Validation ROC\", os.path.join(curr_folder, \"roc_val.png\"))\n",
    "save_roc_curve(labels_test, scores_test, \"Test ROC\", os.path.join(curr_folder, \"roc_test.png\"))\n",
    "\n",
    "save_confusion_matrix(metrics_valid[\"cm\"], f\"Valid - Risk of Macular Edema @ τ={tau_target_sensitivity:.4f} (sens≥{int(target_sensitivity*100)}%)\", os.path.join(curr_folder, \"cm_val_sens.png\"))\n",
    "save_confusion_matrix(metrics_test[\"cm\"], f\"Test - Risk of Macular Edema @ τ={tau_target_sensitivity:.4f} (sens≥{int(target_sensitivity*100)}%)\", os.path.join(curr_folder, \"cm_test_sens.png\"))\n",
    "\n",
    "def fmt(m): return (f\"acc={m['accuracy']:.4f}  auroc={m['auroc']:.4f}  auprc={m['auprc']:.4f}  \"\n",
    "                    f\"prec={m['precision']:.4f}  rec={m['recall']:.4f}  f1={m['f1']:.4f}\")\n",
    "print(\"\\nVALID @ τ_sens:\", fmt(metrics_valid))\n",
    "print(\"TEST  @ τ_sens:\", fmt(metrics_test))\n",
    "print(\"TRAIN @ τ_sens:\", fmt(metrics_train))\n",
    "\n",
    "csv_row = {\n",
    "    # Run context\n",
    "    \"architecture\": architecture,\n",
    "    \"image_size\": image_size,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"init_lr\": init_lr,             \n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"target_sensitivity\": target_sensitivity,\n",
    "    \"operating_tau\": tau_target_sensitivity, # τ chosen on VALIDATION to hit sensitivity target\n",
    "\n",
    "    # TRAIN (evaluated without augmentation)\n",
    "    \"train_acc\": metrics_train[\"accuracy\"],\n",
    "    \"train_auroc\": metrics_train[\"auroc\"],\n",
    "    \"train_auprc\": metrics_train[\"auprc\"],\n",
    "    \"train_prec\": metrics_train[\"precision\"],\n",
    "    \"train_rec\": metrics_train[\"recall\"],\n",
    "    \"train_f1\": metrics_train[\"f1\"],\n",
    "\n",
    "    # VALIDATION (threshold selection split)\n",
    "    \"val_acc\": metrics_valid[\"accuracy\"],\n",
    "    \"val_auroc\": metrics_valid[\"auroc\"],\n",
    "    \"val_auprc\": metrics_valid[\"auprc\"],\n",
    "    \"val_prec\": metrics_valid[\"precision\"],\n",
    "    \"val_rec\": metrics_valid[\"recall\"],\n",
    "    \"val_f1\": metrics_valid[\"f1\"],\n",
    "\n",
    "    # TEST (held-out, honest report)\n",
    "    \"test_acc\": metrics_test[\"accuracy\"],\n",
    "    \"test_auroc\": metrics_test[\"auroc\"],\n",
    "    \"test_auprc\": metrics_test[\"auprc\"],\n",
    "    \"test_prec\": metrics_test[\"precision\"],\n",
    "    \"test_rec\": metrics_test[\"recall\"],\n",
    "    \"test_f1\": metrics_test[\"f1\"],\n",
    "}\n",
    "\n",
    "csv_columns = [\n",
    "    \"architecture\",\"image_size\",\"batch_size\",\"init_lr\",\"optimizer\",\n",
    "    \"target_sensitivity\",\"operating_tau\",\n",
    "    \"train_acc\",\"train_auroc\",\"train_auprc\",\"train_prec\",\"train_rec\",\"train_f1\",\n",
    "    \"val_acc\",\"val_auroc\",\"val_auprc\",\"val_prec\",\"val_rec\",\"val_f1\",\n",
    "    \"test_acc\",\"test_auroc\",\"test_auprc\",\"test_prec\",\"test_rec\",\"test_f1\",\n",
    "]\n",
    "\n",
    "append_row_to_experiments_csv(experiments_csv_path, csv_row, csv_columns)\n",
    "print(f\"\\nAppended metrics → {experiments_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e42bc4-1ccd-4272-a3b8-fa73ffb7bf2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### OLD TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e623c-44b5-4621-ba8b-20625429c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "train_acc = 0\n",
    "val_acc = 0\n",
    "test_acc = 0\n",
    "with open(eval_path, 'w') as f:\n",
    "    eval_gen_train = DataGenerator(images=train_images_orig, image_classes=train_classes_orig, use_augmentation=False)\n",
    "    res = model.evaluate(eval_gen_train)\n",
    "    print('EVAL TRAIN:', res)\n",
    "    f.write('Train loss: {}\\r\\n'.format(res[0]))\n",
    "    f.write('Train acc: {}\\r\\n'.format(res[1]))\n",
    "    train_acc = res[1]\n",
    "\n",
    "    eval_gen_valid = DataGenerator(images=val_images, image_classes=val_classes, use_augmentation=False)\n",
    "    res = model.evaluate(eval_gen_valid)\n",
    "    print('EVAL VAL:', res)\n",
    "    f.write('Val loss: {}\\r\\n'.format(res[0]))\n",
    "    f.write('Val acc: {}\\r\\n'.format(res[1]))\n",
    "    val_acc = res[1]\n",
    "\n",
    "    if not join_test_with_train:\n",
    "        eval_gen_test = DataGenerator(images=test_images, image_classes=test_classes, use_augmentation=False)\n",
    "        res = model.evaluate(eval_gen_test)\n",
    "        print('EVAL TEST:', res)\n",
    "        f.write('Test loss: {}\\r\\n'.format(res[0]))\n",
    "        f.write('Test acc: {}\\r\\n'.format(res[1]))\n",
    "        test_acc = res[1]\n",
    "\n",
    "# Write entry in experiments.csv\n",
    "with open(experiments_file, 'a') as f:\n",
    "    f.write('{},{}{},{},{},{},{},{},{},{},{},{},{},{},{}\\r\\n'.format(experiment_no,\n",
    "                                                                     image_size,\n",
    "                                                                     architecture,\n",
    "                                                                     data_augmentation,\n",
    "                                                                     init_lr,\n",
    "                                                                     optimizer_name,\n",
    "                                                                     monitor_loss,\n",
    "                                                                     batch_size,\n",
    "                                                                     train_acc,\n",
    "                                                                     val_acc,\n",
    "                                                                     test_acc))\n",
    "\n",
    "# Rename current folder\n",
    "curr_folder_new = curr_folder + ' ({})'.format(test_acc)\n",
    "os.rename(curr_folder, curr_folder_new)\n",
    "curr_folder = curr_folder_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3136064-2421-42a5-9466-7dae83c40259",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = create_classifier_model(True, augmenter)\n",
    "\n",
    "# Load warmup weights\n",
    "model_ft.load_weights(warmup_weights_path)\n",
    "\n",
    "# New optimizer with smaller LR for fine-tuning\n",
    "finetune_lr = 3e-4\n",
    "optimizer_ft = tf.keras.optimizers.AdamW(learning_rate=finetune_lr, weight_decay=init_decay)\n",
    "\n",
    "# Re-compile (same loss/metrics for fairness)\n",
    "model_ft.compile(\n",
    "    optimizer=optimizer_ft,\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=[tf.keras.metrics.binary_accuracy]\n",
    "    # Tip: add AUCs when you’re ready:\n",
    "    # metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\"),\n",
    "    #          tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    #          tf.keras.metrics.AUC(curve=\"PR\", name=\"auprc\")]\n",
    ")\n",
    "\n",
    "# Continue training to total epochs (warmup + finetune = epochs)\n",
    "remaining_epochs = max(0, epochs - epochs_warmup)\n",
    "history_ft = model_ft.fit(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    initial_epoch=epochs_warmup,    # purely cosmetic in logs\n",
    "    epochs=epochs_warmup + remaining_epochs,\n",
    "    callbacks=[csv_logger, reduce_lr, early_stopping],\n",
    "    class_weight=class_weight,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Keep the fine-tuned model as your “current” model\n",
    "model = model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd963ae0-07f2-41cf-a556-ee5f4c868431",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(history_ft.history['binary_accuracy'])\n",
    "plt.plot(history_ft.history['val_binary_accuracy'])\n",
    "plt.savefig(os.path.join(curr_folder, 'accuracy.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c02c6-537d-4c37-98de-77881be67228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "    roc_curve, f1_score, confusion_matrix, classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26371e3d-1a28-4965-bc35-0b1b49b72321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_probs_and_labels(model, ds):\n",
    "    \"\"\"Return y_true (0/1) and y_prob (sigmoid probs) from a batched dataset.\"\"\"\n",
    "    y_true, y_prob = [], []\n",
    "    for x_batch, y_batch in ds:\n",
    "        p = model.predict(x_batch, verbose=0).reshape(-1)   # sigmoid output\n",
    "        y_true.append(y_batch.numpy().reshape(-1))\n",
    "        y_prob.append(p)\n",
    "    y_true = np.concatenate(y_true).astype(int)\n",
    "    y_prob = np.concatenate(y_prob)\n",
    "    return y_true, y_prob\n",
    "\n",
    "y_val, p_val = collect_probs_and_labels(model, valid_dataset)\n",
    "\n",
    "auroc  = roc_auc_score(y_val, p_val)\n",
    "auprc  = average_precision_score(y_val, p_val)   # PR-AUC\n",
    "print(f\"Val AUROC: {auroc:.4f} | Val AUPRC: {auprc:.4f}\")\n",
    "\n",
    "# F1-max threshold\n",
    "prec, rec, th = precision_recall_curve(y_val, p_val)\n",
    "f1s = 2*prec*rec / (prec+rec + 1e-12)\n",
    "ix_f1 = np.nanargmax(f1s)\n",
    "tau_f1 = th[max(ix_f1-1, 0)]     # note: precision_recall_curve returns one fewer thresholds than points\n",
    "print(f\"Tau_F1 (val): {tau_f1:.4f}, F1={f1s[ix_f1]:.4f}, P={prec[ix_f1]:.4f}, R={rec[ix_f1]:.4f}\")\n",
    "\n",
    "# Sensitivity (recall) target, e.g., ≥0.90\n",
    "target_recall = 0.90\n",
    "# choose the smallest threshold achieving >= target recall\n",
    "candidates = th[rec[:-1] >= target_recall]   # align lengths\n",
    "tau_rec = candidates.min() if candidates.size else th[-1]\n",
    "print(f\"Tau_sens≥{target_recall:.0%} (val): {tau_rec:.4f}\")\n",
    "\n",
    "def evaluate_at_threshold(y, p, tau, title=\"\"):\n",
    "    y_hat = (p >= tau).astype(int)\n",
    "    cm = confusion_matrix(y, y_hat)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(title or f\"@tau={tau:.4f}\")\n",
    "    print(\"Confusion matrix [[TN, FP],[FN, TP]]:\\n\", cm)\n",
    "    print(f\"Accuracy={((tp+tn)/cm.sum()):.4f}\")\n",
    "    print(f\"Sensitivity/Recall={tp/(tp+fn+1e-12):.4f}  |  Specificity={tn/(tn+fp+1e-12):.4f}\")\n",
    "    print(f\"Precision={tp/(tp+fp+1e-12):.4f}  |  F1={f1_score(y, y_hat):.4f}\")\n",
    "    print(classification_report(y, y_hat, digits=4))\n",
    "\n",
    "evaluate_at_threshold(y_val, p_val, tau_f1, title=\"Validation @ F1-max τ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be26b9d-f409-4b3d-bfee-80b2e44e849e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
